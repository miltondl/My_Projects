{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e31849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio-safe Patch Report Automation\n",
    "\n",
    "# Install Dataloop library\n",
    "!pip install dtlpy\n",
    "\n",
    "import dtlpy as dl\n",
    "from datetime import date, timedelta\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# -------------------------------\n",
    "# Mock BigQuery client (replace with real credentials if needed)\n",
    "# -------------------------------\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# -------------------------------\n",
    "# Functions to get date ranges\n",
    "# -------------------------------\n",
    "def get_yesterday_and_today():\n",
    "    today = date.today()\n",
    "    yesterday = today - timedelta(days=1)\n",
    "    return yesterday.strftime(\"%Y-%m-%d\"), today.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Functions to get the last day updated\n",
    "# -------------------------------\n",
    "def get_last_date():\n",
    "    # Use %%bigquery to execute a SQL query and store results in a DataFrame\n",
    "    query = f\"\"\"\n",
    "    SELECT MAX(date) FROM `taranis-bi.TS_AG.patches_quality_report_all`\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and store the result in the DataFrame\n",
    "    from google.cloud import bigquery\n",
    "    client = bigquery.Client(project='taranis-bi')\n",
    "    results = client.query(query).to_dataframe()\n",
    "\n",
    "    return str(results.iloc[0][0])\n",
    "\n",
    "# -------------------------------\n",
    "# Function to simulate fetching patches report\n",
    "# -------------------------------\n",
    "def get_patches_report(star_date, finish_date):\n",
    "    # Use %%bigquery to execute a SQL query and store results in a DataFrame\n",
    "    query = f\"\"\"\n",
    "    SELECT * FROM `human_patches_clear_data`\n",
    "    WHERE is_correct_answer is False and date > '{star_date}' and date < '{finish_date}'\n",
    "    and is_correct_answer is False\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query and store the result in the DataFrame\n",
    "    from google.cloud import bigquery\n",
    "    client = bigquery.Client(project='project_name')\n",
    "    results = client.query(query).to_dataframe()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Function to extract image links from patch URLs\n",
    "# -------------------------------\n",
    "\n",
    "def get_appsheet_report(results):\n",
    "    list_all_patches = []\n",
    "    for row in range(len(results)):\n",
    "    # print (row)\n",
    "        list_all_patches.append(dict(results.iloc[row]))\n",
    "    list_all_patches\n",
    "\n",
    "    patch_report_list = []\n",
    "    for row in list_all_patches:\n",
    "        url = row[\"patch_url\"]\n",
    "\n",
    "        # Make the GET request\n",
    "        response = requests.get(url)\n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content with BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            # Find all image tags and extract their src attribute\n",
    "            image_url = [img[\"src\"] for img in soup.find_all(\"img\")][0]\n",
    "            # Print or return the list of image URLs\n",
    "            row_dict = {}\n",
    "            for k in row.keys():\n",
    "                row_dict[k] = row[k]\n",
    "                row_dict['link'] = image_url\n",
    "                row_dict['tagger'] = None\n",
    "                patch_report_list.append(row_dict)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve images. Status code: {response.status_code}\")\n",
    "\n",
    "    # You can return or print the patch_report_list as needed\n",
    "    patch_report_list = pd.DataFrame(patch_report_list)\n",
    "\n",
    "    return patch_report_list\n",
    "\n",
    "# -------------------------------\n",
    "# Mock function to simulate fetching tagger info from Dataloop\n",
    "# -------------------------------\n",
    "def get_creator_metadata(item_id):\n",
    "    \"\"\"\n",
    "    Returns dummy tagger info for a given annotation item.\n",
    "    \"\"\"\n",
    "    return {item_id: [(\"Tagger_1\", \"2025-09-07T10:00:00\")]}\n",
    "\n",
    "\n",
    "dataloop_project = dl.projects.get(project_id=\"project_id\")\n",
    "\n",
    "def get_tagger(row):\n",
    "\n",
    "    \"\"\"\n",
    "    Simulate fetching taggers for each patch.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset_id = row['dataloop_link'].split('datasets/')[1].rsplit('/items')[0]\n",
    "    except:\n",
    "        dataset_id = None\n",
    "    annotation_item_ids = row['annotation_item_ids']\n",
    "\n",
    "    if pd.isnull(annotation_item_ids) or dataset_id is None:\n",
    "        return None\n",
    "\n",
    "    if dataset_id:\n",
    "        dataset = dataloop_project.datasets.get(dataset_id=dataset_id)\n",
    "        filters = dl.Filters()\n",
    "        filters.add(field=\"metadata.annotation_item_id\", values=json.loads(annotation_item_ids), operator=dl.FiltersOperations.IN)\n",
    "        list_items = dataset.items.get_all_items(filters=filters)\n",
    "        taggers = [get_creator_metadata(item) for item in list_items]\n",
    "        print (annotation_item_ids)\n",
    "        return taggers\n",
    "\n",
    "    return None\n",
    "\n",
    "# -------------------------------\n",
    "# Main pipeline\n",
    "# -------------------------------\n",
    "start_date, finish_date = get_yesterday_and_today()\n",
    "\n",
    "# Step 1: Fetch patches report\n",
    "results = get_patches_report(start_date, finish_date)\n",
    "\n",
    "# Step 2: Extract image links\n",
    "patch_report_list = get_appsheet_report(results)\n",
    "\n",
    "# Step 3: Assign taggers\n",
    "patch_report_list['tagger'] = patch_report_list.apply(get_tagger, axis=1)\n",
    "\n",
    "\n",
    "# Step 4: Clean dataset for portfolio\n",
    "patch_report_list = patch_report_list.drop_duplicates(subset=['patch_id'])\n",
    "patch_report_list['patch_id'] = patch_report_list['patch_id'].astype(int)\n",
    "\n",
    "# Step 5: Adding the tagger name in each patch \n",
    "patch_report_list =  patch_report_list[['image_id', 'annotation_item_ids', 'dataloop_link']]\n",
    "patch_report_list['tagger'] = patch_report_list.apply(get_tagger, axis=1)\n",
    "\n",
    "\n",
    "# Step 6: Upload to BigQuery (Portfolio-safe example)\n",
    "\n",
    "\"\"\"\n",
    "client = bigquery.Client(project='portfolio-project')\n",
    "table_id = \"portfolio_dataset.patch_reports\"\n",
    "job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_APPEND\")\n",
    "job = client.load_table_from_dataframe(patch_report_list, table_id, job_config=job_config)\n",
    "job.result()\n",
    "print(f\"Table {table_id} uploaded successfully.\")\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
